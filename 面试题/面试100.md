### Java

#### 面向对象有哪些特征

- 封装：隐藏了类的内部实现机制，可以在不影响使用的情况下改变类的内部结构，同时也保护了数据。对外界而已它的内部细节是隐藏的，暴露给外界的只是它的访问方法。
- 继承：是为了重用父类代码。两个类若存在IS-A的关系就可以使用继承。，同时继承也为实现多态做了铺垫。
- 多态：就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量倒底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。因为在程序运行时才确定具体的类，这样，不用修改源程序代码，就可以让引用变量绑定到各种不同的类实现上，从而导致该引用调用的具体方法随之改变，即不修改程序代码就可以改变程序运行时所绑定的具体代码，让程序可以选择多个运行状态，这就是多态性。

#### jdk8新特性

> 1. Interface
>
>    新增default修饰方法，是普通实例方法，可以用`this`调用，可以被子类继承、重写
>
>    新增static修饰方法，使用和一般静态方法一样，但是不能被子类继承，只能通过``Interface`调用
>
> 2. functional-interface函数式接口
>
> 3. Lambda表达式
>
>    Lambda表达式是一个匿名函数，java 8允许吧函数作为参数传递进方法中，lambda 表达式可以引用外边变量，但是该变量默认拥有 final 属性，不能被修改，如果修改，编译时就报错。
>
> 4. 方法引用
>
>    java 8允许使用`::`关键字来传递方法或者构造函数引用，无论如何，表达式返回的类型必须是functional-interface
>
> 5. Stream
>
>    Stream不存储数据，它可以检索和逻辑处理集合数据，包括筛选、排序、统计、计数等。可以分为Stream串行流、ParallelStream并行流，可多线程执行
>
> 6. Optional
>
>    使用 `Optional` 解决 NPE（`java.lang.NullPointerException`）问题，它就是为 NPE 而生的，其中可以包含空值或非空值。
>
> 7. Date-Time API

#### java中抽象类和接口有什么区别

- 构造方法：抽象类可以有构造方法，接口中不能有构造方法
- 成员变量：抽象类可以有普通成员变量，任意访问类型的的静态成员变量。接口中不能有普通成员变量，只能有`public static final`修饰的静态变量
- 方法：抽象类可以包含普通方法和抽象方法，接口中所有方法都是必须是抽象方法。抽象类中可以包含静态方法，接口中不能包含静态方法
- 访问类型：抽象类中方法可以是`public`、`protected`、默认，但是接口中的抽象方法只能是`public`，并且默认是`public abstract`类型
- 实现：抽象类单继承，接口可以多继承
- 应用上：抽象类主要用于抽象类别，接口主要用来抽象方法功能，当我们来抽象一个狗的对象时，可以使用抽象类来描述狗，具体到那种类型的狗时可以继承这个抽象类，当我们描述一类动作时，比如猫和狗都有跑这个能力，就可以实现接口来实现跑这个功能

#### `hashcode`和`equals`如何使用

自定义类中的的`equals`和==是一样的，比较的是内存地址，当重写`equals`方法时，必须也要同事重写`hashcode`方法，因为在比如`HashMap`中，比较两个对象是否相等，首先是调用`hashcode`来比较，再用`equals`比较，如果使用`equals`比较相同，那么比较`hashcode`时也必须相同

#### `java`代理的几种实现方式

- 静态代理：自己手动实现
- 动态代理：
  1. `JDK`动态代理，代理类必须实现接口
  2. `CGLIB`动态代理，代理类可以不用实现接口

#### ==和`equals`有哪些区别

`Object`类中，`equals`用==实现，对象都是比较内存地址，基本数据类型比较值，但是可以重写`equals`方法来实现内容比较，比如`String`中`equals`方法就是重写过的。

#### `java`异常处理机制是什么

处理机制为：抛出异常，捕捉异常

抛出异常的方法：`throws`和`throw`：

- `throws`：通常用在声明方法时，用来指定方法可能抛出的异常，多个异常使用逗号分隔，`throws`关键字将异常抛给上一级，如果不想处理该异常，可以继续向上抛出，但最终要有能够处理该异常的代码。

- `throw`：通常用在方法体中或者用来抛出用户自定义异常，并且抛出一个异常对象。程序在执行到throw语句时立即停止，如果要捕捉`throw`抛出的异常，则必须使用`try-catch`语句块或者`try-catch-finally`语句。

  `try-catch-finally`语句：首先执行`try`中代码，如果代码执行正常就就继续执行`finally`代码块，如果发生异常且被`catch`捕获到就执行`catch`代码块，然后执行`finally`代码块。

#### `java`中重写和重载的区别

重写：实质是子类对父类的函数进行了重定义。若子类中的方法与父类中的某一方法具有相同的方法名、返回类型和参数表，则新方法将覆盖原有的方法，如需父类中原有的方法则可使用 super 关键字。重写方法访问修饰符不能小于被重写方法，抛出的异常必须是被重写方法抛出异常或者其子异常

重载：是让类以统一的方式处理不同类型数据的一种手段，实质表现就是多个具有不同的参数个数或者类型的同名函数（返回值类型可随意，不能以返回类型作为重载函数的区分标准）同时存在于同一个类中，是一个类中多态性的一种表现，调用时通过参数判断具体方法。

重载与重写是 `Java 多态性`的不同表现。

- 重写是父类与子类之间多态性的表现，在运行时起作用（动态多态性，譬如实现动态绑定）
- 而重载是一个类中多态性的表现，在编译时起作用（静态多态性，譬如实现静态绑定）。

#### `String`、`StringBuffer`、`StringBuilder`区别和使用场景

`String`：字符数组被final修饰，不可变，如果进行字符串操作是新建一个`String`。

`StringBuffer`：可变字符串，线程安全，适用于多线程环境操作字符串

`StringBuilder`：可变字符串，线程不安全，适用于单线程环境操作字符串，

#### 怎么声明一个类不会被继承

- 使用`final`修饰类
- 私有化构造器

### Java集合

#### 高并发集合有哪些

- 早期线程安全集合

  `Vector`：类似于`ArrayList`，可变数组实现

  `HashTable`：类似于`HashMap`，但是它的key和value都不能为null

- `Collections`包装方法

  ```java
  List<E> synArrayList = Collections.synchronizedList(new ArrayList<E>());
  
  Set<E> synHashSet = Collections.synchronizedSet(new HashSet<E>());
  
  Map<K,V> synHashMap = Collections.synchronizedMap(new HashMap<K,V>());
  ```

  `Collections`针对每种集合都声明了一个线程安全的包装类，在原集合的基础上添加了锁对象，集合中的每个方法都通过这个锁对象实现同步

- `java.util.concurrent`包中的集合

  1. `ConcurrentHashMap`：

     `ConcurrentHashMap`和`HashTable`都是线程安全的集合，它们的不同主要是加锁粒度上的不同。`HashTable`的加锁方法是给每个方法加上synchronized关键字，这样锁住的是整个Table对象。而`ConcurrentHashMap`是更细粒度的加锁

     在`JDK1.8`之前，`ConcurrentHashMap`加的是分段锁，也就是`Segment`锁，每个`Segment`含有整个`table`的一部分，这样不同分段之间的并发操作就互不影响
     `JDK1.8`对此做了进一步的改进，它取消了`Segment`字段，直接在`table`元素上加锁，实现对每一行进行加锁，进一步减小了并发冲突的概率

  2. `CopyOnWriteArrayList`和`CopyOnWriteArraySet`

     它们是加了写锁的`ArrayList`和`ArraySet`，锁住的是整个对象，但读操作可以并发执行，`CopyOnWriteArraySet`底层使用`CopyOnWriteArrayList`实现

  3. 除此之外还有`ConcurrentSkipListMap`、`ConcurrentSkipListSet`、`ConcurrentLinkedQueue`、`ConcurrentLinkedDeque`等，至于为什么没有`ConcurrentArrayList`，原因是无法设计一个通用的而且可以规避`ArrayList`的并发瓶颈的线程安全的集合类，只能锁住整个`list`，这用`Collections`里的包装类就能办到

#### `HashMap`和`HashTable`的区别

线程安全不同：

- `Hashtable`的几乎所有函数都是同步的，即它是线程安全的，支持多线程。
- `HashMap`的函数则是非同步的，它不是线程安全的。

对null值的处理不同：

- `HashMap`的key、value都可以为null。
- `Hashtable`的key、value都不可以为null。

容量的初始值 和 增加方式都不一样：

- `HashMap`默认的容量大小是16；增加容量时，每次将容量变为“原始容量x2”。
- `Hashtable`默认的容量大小是11；增加容量时，每次将容量变为“原始容量x2 + 1”。

添加key-value时的hash值算法不同

- `HashMap`添加元素时，是使用自定义的哈希算法。
- `Hashtable`没有自定义哈希算法，而直接采用的key的hashCode()。

#### `HashMap`有哪些线程安全的方式

- 使用`Collections.synchronizedMap(new HashMap<String, Strinig>())`获取线程安全`Map`
- 使用`ConcurrentHashMap`

#### `HashMap`在扩容上做了哪些优化

`JDK7`

- `HashMap`的内部数据保存的都是链表。因此逻辑相对简单：在准备好新的数组后，map会遍历数组的每个“桶”，然后遍历桶中的每个Entity，重新计算其hash值（也有可能不计算），找到新数组中的对应位置，以头插法插入新的链表。

`JDK8`扩容

1. 空参数的构造函数：实例化的`HashMap`默认内部数组是null，即没有实例化。第一次调用put方法时，则会开始第一次初始化扩容，长度为16。
2. 有参构造函数：用于指定容量。会根据指定的正整数找到不小于指定容量的2的幂数，将这个数设置赋值给**阈值**（threshold）。第一次调用put方法时，会将阈值赋值给容量，然后让 阈值=容量*负载因子（因此并不是我们手动指定了容量就一定不会触发扩容，超过阈值后一样会扩容！！)
3. 如果不是第一次扩容，则容量变为原来的2倍，阈值也变为原来的2倍。*（容量和阈值都变为原来的2倍时，负载因子还是不变）*

`JDK8`性能有了大大的提升：由于数组的容量是以2的幂次方扩容的，那么一个Entity在扩容时，新的位置要么在原位置，要么在原长度+原位置的位置。数组长度变为原来的2倍，表现在二进制上就是多了一个高位参与数组下标确定。此时，一个元素通过hash转换坐标的方法计算后，恰好出现一个现象：最高位是0则坐标不变，最高位是1则坐标变为“10000+原坐标”，即“原长度+原坐标”。

#### 为什么`HashMap`扩容的时候是两倍

1. 源码计算存储位置时`(n-1)&hash(key)`，容量为2的幂次方时，`n-1`的二进制会全为1，位运算时可以充分散列，避免不必要的哈希冲突。
2. 扩容迁移的时候不需要再重新通过哈希定位新的位置了。扩容后，元素新的位置，要么在原脚标位，要么在原脚标位+扩容长度这么一个位置，是否移位，由扩容后表示的最高位是否1为所决定，由于移动的方向只有一个，即向高位移动。

#### `ArrayList`和`linkedList`有什么区别

- 数据结构不同：`ArrayList`底层使用Array（数组）实现，`LinkedList`底层使用双向链表实现
- `LinkedList`不支持高效的随机访问，而`ArrayList`支持，快速随机访问就是通过元素的序号快速获取元素对象（对应于`get(int index)`方法。
- `ArrayList` 的空 间浪费主要体现在在 `list` 列表的结尾会预留一定的容量空间，而 `LinkedList` 的空间花费则体现在它的每一个元素都需要消耗比 `ArrayList`更多的空间（因为要存放直接后继和直接前驱以及数据）。
- `ArrayList`可以看做是一个能够自动增长的数组，扩容时按照当前容量1.5倍进行扩容

#### comparable 和 Comparator 的区别

> `comparable`接口实际上是出自于`java.lang`包，它有一个`compareTo`方法来排序，需要排序的类继承这个接口重载`comparable`方法。
>
> `comparator`接口出自`java.util`包，它有一个`compare(Object obj1,Object obj2)`方法来排序

#### Queue和Deque的区别

> queue是单端队列，一般遵循**先进先出（FIFO）**规则
>
> Deque是双端队列，在队列两端都可以插入或者删除元素，事实上，Deque还提供有`push()`和`pop()`等其他方法，可用于模拟栈

#### `ArrayDeque`与`LinkedList`的区别

> 都实现了Deque接口：
>
> - `ArrayDeque`是基于可变长的数组和双指针来实现的，而`LinkedList`是通过链表来实现的。
> - `ArrayDeque`不支持存储Null数据，但是`LinkedList`支持。
> - `ArrayDeque`在`jdk1.6`引入，`linkedList`在`jdk1.2`时就已经存在了。
> - `ArrayDeque`插入时操作为O(1)。`LinkedList`每次插入数据时要申请新的堆空间。

### JVM

#### 什么情况下会发生栈内存溢出

> 栈是线程私有的，他的生命周期与线程相同，每个方法在执行的时候都会创建一个栈帧，用来存储局部变量表，操作数栈，动态链接，方法出口等信息。局部变量表又包含基本数据类型，对象引用类型;
>
> 如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常，方法递归调用产生这种结果;
>
> 如果Java虚拟机栈可以动态扩展，并且扩展的动作已经尝试过，但是无法申请到足够的内存去完成扩展，或者在新建立线程的时候没有足够的内存去创建对应的虚拟机栈，那么Java虚拟机将抛出一个OutOfMemory异常;
>
> 参数-Xss 去调整JVM栈的大小。

#### 介绍一下JVM内存模型

> 线程私有：
>
> 1. 程序计数器
>
>    程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。
>
>    注意：程序计数器是唯一一个不会出现 `OutOfMemoryError` 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。
>
> 2. 虚拟机栈
>
>    它的生命周期和线程相同，描述的是 Java 方法执行的内存模型，每次方法调用的数据都是通过栈传递的。
>
>    实际上，Java 虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息。
>
>    局部变量表主要存放了编译期可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用
>
>    Java 虚拟机栈会出现两种错误：`StackOverFlowError` 和 `OutOfMemoryError`
>
> 3. 本地方法栈
>
>    和虚拟机栈所发挥的作用非常相似，区别是：虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 `Native` 方法服务。 在 `HotSpot` 虚拟机中和 `Java` 虚拟机栈合二为一。
>
>    也会出现 `StackOverFlowError` 和 `OutOfMemoryError` 两种错误。
>
> 线程共享：
>
> 1. 堆
>
>    Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。
>
>    Java 堆是垃圾收集器管理的主要区域，因此也被称作`GC` 堆（Garbage Collected Heap）。
>
> 2. 方法区
>
>    方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然 **Java 虚拟机规范把方法区描述为堆的一个逻辑部分**，但是它却有一个别名叫做 **Non-Heap（非堆）**，目的应该是与 Java 堆区分开来。
>
> 3. 直接内存 (非运行时数据区的一部分)
>
> 运行时常量池：
>
> 运行时常量池是方法区的一部分。用于存放编译期间生成的各种字面量和符号引用。
>
> 1. `JDK1.7` 之前运行时常量池逻辑包含字符串常量池存放在方法区, 此时 `hotspot` 虚拟机对方法区的实现为永久代
> 2. `JDK1.7` 字符串常量池被从方法区拿到了堆中, 这里没有提到运行时常量池,也就是说字符串常量池被单独拿到堆,运行时常量池剩下的东西还在方法区, 也就是 `hotspot` 中的永久代 。
> 3. `JDK1.8 hotspot `移除了永久代用元空间(`Metaspace`)取而代之, 这时候字符串常量池还在堆, 运行时常量池还在方法区, 只不过方法区的实现从永久代变成了元空间(`Metaspace`)

#### 新生代为什么要分为Eden区和两个Survivor区

1. 没有`Survivor`，`Eden`区每进行一次`Minor GC`，存活的对象就会被送到老年代。老年代很快被填满，触发`Major GC`老年代的内存空间远大于新生代，进行一次`Full GC`消耗的时间比`Minor GC`长得多,所以需要分为`Eden`和`Survivor`，`Survivor`的存在是为了筛选被送到老年代的对象，进而减少`Full GC`的发生
2. 设置两个`Survivo`r区最大的好处就是解决了碎片化，刚刚新建的对象在`Eden`中，经历一次`Minor  GC`，`Eden`中的存活对象就会被移动到第一块`survivor space S0`，`Eden`被清空;等`Eden`区再满了，就再触发一次`Minor  GC`，`Eden`和`S0`中的存活对象又会被复制送入第二块`survivor space  S1`(这个过程非常重要，因为这种复制算法保证了`S1`中来自`S0`和`Eden`两部分的存活对象占用连续的内存空间，避免了碎片化的发生)。

#### 类加载过程

系统加载Class类型的文件主要有三步：加载-->连接-->初始化。连接过程又可分为三步：验证-->准备-->解析

#### 什么是类加载器，类加载器有哪些

> 实现通过类的权限定名获取该类的二进制字节流的代码块叫做类加载器。主要有以下三种类加载器：
>
> 1. **`BootstrapClassLoader`(启动类加载器)** ：最顶层的加载类，由 C++实现，负责加载 `%JAVA_HOME%/lib`目录下的 jar 包和类或者被 `-Xbootclasspath`参数指定的路径中的所有类。
> 2. **`ExtensionClassLoader`(扩展类加载器)** ：主要负责加载 `%JRE_HOME%/lib/ext` 目录下的 jar 包和类，或被 `java.ext.dirs` 系统变量所指定的路径下的 jar 包。
> 3. **`AppClassLoader`(应用程序类加载器)** ：面向我们用户的加载器，负责加载当前应用 `classpath` 下的所有 jar 包和类。
>
> 可以通过继承`java.lang.ClassLoader`自定义类加载器。

#### 说一说双亲委派机制

> 每一个类都有一个对应它的类加载器。系统中的 `ClassLoader` 在协同工作的时候会默认使用 **双亲委派模型** 。即在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。加载的时候，首先会把该请求委派给父类加载器的 `loadClass()` 处理，因此所有的请求最终都应该传送到顶层的启动类加载器 `BootstrapClassLoader` 中。当父类加载器无法处理时，才由自己来处理。当父类加载器为 null 时，会使用启动类加载器 `BootstrapClassLoader` 作为父类加载器。
>
> 双亲委派模型的实现代码非常简单，逻辑非常清晰，都集中在 `java.lang.ClassLoader` 的 `loadClass()` 中
>
> 双亲委派模型保证了 Java 程序的稳定运行，可以避免类的重复加载（`JVM` 区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类），也保证了 Java 的核心 `API` 不被篡改。如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个称为 `java.lang.Object` 类的话，那么程序运行的时候，系统就会出现多个不同的 `Object` 类。

#### 常用`JVM`参数

`JVM`的参数非常之多，这里只列举比较重要的几个，通过各种各样的搜索引擎也可以得知这些信息。

| 参数名称                   | 含义                                                       | 默认值               | 说明                                                         |
| -------------------------- | ---------------------------------------------------------- | -------------------- | ------------------------------------------------------------ |
| -Xms                       | 初始堆大小                                                 | 物理内存的1/64(<1GB) | 默认(MinHeapFreeRatio参数可以调整)空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制. |
| -Xmx                       | 最大堆大小                                                 | 物理内存的1/4(<1GB)  | 默认(MaxHeapFreeRatio参数可以调整)空余堆内存大于70%时，JVM会减少堆直到 -Xms的最小限制 |
| -Xmn                       | 年轻代大小(1.4or later)                                    |                      | 注意：此处的大小是（eden+ 2 survivor space).与jmap -heap中显示的New gen是不同的。整个堆大小=年轻代大小 + 老年代大小 + 持久代（永久代）大小.增大年轻代后,将会减小年老代大小.此值对系统性能影响较大,Sun官方推荐配置为整个堆的3/8 |
| -XX:NewSize                | 设置年轻代大小(for 1.3/1.4)                                |                      |                                                              |
| -XX:MaxNewSize             | 年轻代最大值(for 1.3/1.4)                                  |                      |                                                              |
| -XX:PermSize               | 设置持久代(perm gen)初始值                                 | 物理内存的1/64       |                                                              |
| -XX:MaxPermSize            | 设置持久代最大值                                           | 物理内存的1/4        |                                                              |
| -Xss                       | 每个线程的堆栈大小                                         |                      | JDK5.0以后每个线程堆栈大小为1M,以前每个线程堆栈大小为256K.根据应用的线程所需内存大小进行 调整.在相同物理内存下,减小这个值能生成更多的线程.但是操作系统对一个进程内的线程数还是有限制的,不能无限生成,经验值在3000~5000左右一般小的应用， 如果栈不是很深， 应该是128k够用的 大的应用建议使用256k。这个选项对性能影响比较大，需要严格的测试。（校长）和threadstacksize选项解释很类似,官方文档似乎没有解释,在论坛中有这样一句话:-Xss is translated in a VM flag named ThreadStackSize”一般设置这个值就可以了 |
| -XX:NewRatio               | 年轻代(包括Eden和两个Survivor区)与年老代的比值(除去持久代) |                      | -XX:NewRatio=4表示年轻代与年老代所占比值为1:4,年轻代占整个堆栈的1/5Xms=Xmx并且设置了Xmn的情况下，该参数不需要进行设置。 |
| -XX:SurvivorRatio          | Eden区与Survivor区的大小比值                               |                      | 设置为8,则两个Survivor区与一个Eden区的比值为2:8,一个Survivor区占整个年轻代的1/10 |
| -XX:+DisableExplicitGC     | 关闭System.gc()                                            |                      | 这个参数需要严格的测试                                       |
| -XX:PretenureSizeThreshold | 对象超过多大是直接在旧生代分配                             | 0                    | 单位字节 新生代采用Parallel ScavengeGC时无效另一种直接在旧生代分配的情况是大的数组对象,且数组中无外部引用对象. |
| -XX:ParallelGCThreads      | 并行收集器的线程数                                         |                      | 此值最好配置与处理器数目相等 同样适用于CMS                   |
| -XX:MaxGCPauseMillis       | 每次年轻代垃圾回收的最长时间(最大暂停时间)                 |                      | 如果无法满足此时间,JVM会自动调整年轻代大小,以满足此值.       |

#### `GC`如何判断对象可以回收

> 1. 引用计数法
>
>    给对象添加一个引用计数器，每当有一个地方引用它，计数器就加1；引用失效，计数器就减1；这个方法实现简单，效率高，但是目前主流的虚拟机都没有选择这个算法来管理内存，主要原因就是它很难解决对象之间相互循环引用的问题。
>
> 2. 可达性分析算法
>
>    基本思想就是通过一系列的“`GC Roots`”的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当对象到`GC Roots`没有任何引用链时，则证明这个对象是不可用的，可以被回收。
>
>    可以作为`GC Roots`的对象
>
>    - 虚拟机栈（栈帧中的本地变量表）中引用的对象
>    - 本地方法栈中引用的对象
>    - 方法区中类静态属性引用的对象
>    - 方法区中常量引用的对象
>    - 所有被同步锁持有的对象

#### 垃圾回收算法有哪些

> 1. 标记-清除算法
>
>    该算法分为**标记**和**清除**两个阶段：首先标记出所有不需要回收的对象，在标记后统一回收所有没有被标记的对象。这种算法有两个明显的问题：
>
>    - 效率问题
>    - 空间问题（标记清除后会产生大量不连续的碎片）
>
> 2. 标记-复制算法
>
>    该算法将内存分为大小相同的两块，每次使用其中一块，当一块内存使用完后，将存活的对象复制到另一快内存上去，然后把空间一次清除掉。
>
> 3. 标记-整理算法
>
>    根据老年代的特点提出的一种标记算法，**标记**存活对象后，让所有存活对象向一端移动，然后直接清除掉剩余内存空间

#### 有哪些垃圾收集器

> 1. `Serial`收集器
>
>    `Serial`（串行）收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的 **“单线程”** 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ **"Stop The World"** ），直到它收集结束。
>
>    **新生代采用标记-复制算法，老年代采用标记-整理算法。**
>
> 2. `ParNew`收集器
>
>    `ParNew` 收集器其实就是 Serial 收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样。
>
>    **新生代采用标记-复制算法，老年代采用标记-整理算法。**
>
> 3. `Parallel Scavenge` 收集器
>
>    `Parallel Scavenge` 收集器也是使用标记-复制算法的多线程收集器，它看上去几乎和 `ParNew` 都一样。**Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。**
>
>    **新生代采用标记-复制算法，老年代采用标记-整理算法。这是 JDK1.8 默认收集器**
>
> 4. `Serial Old` 收集器
>
>    **Serial 收集器的老年代版本**，它同样是一个单线程收集器。它主要有两大用途：一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途是作为 CMS 收集器的后备方案。
>
> 5. `Parallel Old` 收集器
>
>    **Parallel Scavenge 收集器的老年代版本**。使用多线程和“标记-整理”算法。在注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。
>
> 6. `CMS` 收集器
>
>    `CMS`（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。`CMS`（Concurrent Mark Sweep）收集器是 `HotSpot` 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。主要优点：**并发收集、低停顿**。但是它有下面三个明显的缺点：
>
>    - 对CPU资源敏感
>    - 无法处理浮动垃圾
>    - 使用**标记-清除**算法会导致收集结束时会有大量空间碎片产生
>
> 7. `G1`收集器
>
>    **`G1` (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 `GC` 停顿时间要求的同时,还具备高吞吐量性能特征.**它具备以下特点：
>
>    1. 并行与并发：`G1` 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 `GC` 动作，`G1` 收集器仍然可以通过并发的方式让 `java` 程序继续执行。
>    2. 分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。
>    3. 空间整合：G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。
>    4. 可预测的停顿：这是 `G1` 相对于 `CMS` 的另一个大优势，降低停顿时间是 `G1` 和 `CMS` 共同的关注点，但 `G1` 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。

### JUC

#### 什么是线程和进程

> 进程：程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。
>
> 线程：线程与进程相似，但线程是一个比进程更小的执行单位，一个进程在执行过程中可以产生多个线程。与进程不同的是多个线程共享进程的堆和方法区资源。但是每个线程有自己的程序计数机、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间切换工作，负担要比进程小得多，线程也被称为轻量级进程
>
> **线程是进程划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反。**

#### 什么是线程死锁，如何避免死锁

> 多个线程同时被阻塞，它们中的一个或者全部都在等待摸个资源被释放，由于线程被无限期地阻塞，因此程序不可能正常终止。
>
> 例如线程A持有资源1，线程B持有资源2，它们同时都想申请对方资源，所以两个线程就会互相等待进入死锁。
>
> 避免死锁：
>
> 1. **破坏请求与保持条件** ：一次性申请所有的资源。
> 2. **破坏不剥夺条件** ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
> 3. **破坏循环等待条件** ：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。

#### 说说 sleep() 方法和 wait() 方法区别和共同点?

> - 主要区别：`sleep()`方法没有释放锁，而`wait()`方法释放了锁
> - 两者都可以暂停线程的执行。
> - `wait()`通常被用于线程间交互/通信，`sleep()`通常被用于暂停执行。
> - `wait()`方法被调用后，线程不会自动苏醒，需要别的线程调用同一对象上的`notify()`或者`notifyAll()`方法。`sleep()`方法执行后，线程会自动苏醒。或者可以使用`wait(long timeout)`超时后线程会自动苏醒。

#### 说一说并发和并行的区别

> 并发：同一时间段，多个任务都在执行（单位时间内不一定同时执行）
>
> 并行：单位时间内，多个任务同时执行

#### 怎么使用synchronized关键字

> 1. 修饰实例方法，作用于当前对象实例加锁。
> 2. 修饰静态方法，当前类加锁，会作用于类的所有对象实例。
> 3. 修饰代码块，指定加锁对象，对给定对象/类加锁

#### 谈谈你对volatile的理解

> volatile是Java虚拟机提供的轻量级同步机制
>
> 1. 保证可见性
> 2. 不保证原子性
> 3. 禁止指令重排

#### 说说ThreadLocal

> 创建了一个`ThreadLocal`变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是`ThreadLocal`变量名的由来。他们可以使用 `get（）` 和 `set（）` 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。

#### 谈谈你对`CAS`的理解

> `CAS`就是`compareAndSet`，即比较并交换,是一种实现并发算法时常用到的技术。 
>
> 缺点：
>
> 1. 循环时间长开销大，我们可以看到`getAndAddInt`方法中有一个`dowhile`循环，如果`CAS`一直失败，会一直保持尝试。如果`CAS`长时间一直不成功，可能给`CPU`带来很大的开销。
> 2. 只能保证一个共享变量的原子性。当对一个共享变量执行操作时，我们可以使用循环`CAS`的方式保证原子性操作，但是对多个共享变量的操作时，循环`CAS`就无法保证操作的原子性了，这个时候可以用锁来保证原子性。
> 3. 会出现`ABA`问题，可以使用时间戳原子引用来解决这个问题。简单的说就是在修改数值的时候带上一个版本号。

#### 阻塞队列

1. `ArrayBlockingQueue`：由数组结构组成的有界阻塞队列
2. `LinkedBlockingQueue`：由链表结构组成的有界阻塞队列，大小默认`Integer.MAX_VALUE`
3. `PriorityBlockingQueue`：支持优先级排序的无界队列
4. `DelayQueue`：使用优先级队列实现的延迟无界阻塞队列
5. `SynchronousQueue`：不存储元素的阻塞队列
6. `LinkedTransferQueue`：链表组成的无界阻塞队列
7. `LinkedBlockingDeque`：链表组成的双向阻塞队列

| 方法类型 | 抛出异常  | 特殊值     | 阻塞     | 超时                   |
| -------- | --------- | ---------- | -------- | ---------------------- |
| 插入     | add（e）  | offer（e） | put（e） | offer（e，time，unit） |
| 移除     | remove()  | poll()     | take（） | poll（time，unit）     |
| 检查     | element() | peek()     |          |                        |

#### synchronized和Lock有什么区别？用新的Lock有什么好处？举例说说

- 原始构成
  1. synchronized属于JVM层面，底层通过monitor对象来完成，wait/notify等方法也依赖与monitor对象只能在同步代码块或方法中才能调用
  2. Lock是具体类，是`API`层面的锁
- 使用方法
  1. synchronized不需要手动释放锁
  2. ReentrantLock需要手动释放锁，否则可能会造成死锁现象
- 等待是否可中断
  1. synchronized不可中断，除非抛异常或者正常执行完
  2. ReentrantLock可中断
     1. 设置超时方法tryLock（long timeout，TimeUnit unit）
     2. lockInterruptibly()放入代码块中，调用interrupt()方法中断
- 是否公平
  1. synchronized非公平
  2. ReentrantLock都可以实现
- 锁绑定多个条件Condition
  1. synchronized没有
  2. ReentrantLock可以实现分组唤醒线程，精确唤醒

#### 线程池用过吗？ThreadPoolExecutor谈谈你的理解？

线程池主要工作是控制运行的线程数量，实现线程复用。

- 降低资源消耗。通过复用线程降低线程创建和销毁造成资源消耗
- 提高响应速度。任务到达时，立即执行
- 提高线程的可管理性。线程是稀缺资源，不能无限制创建，使用线程池可以进行统一分配，监控调优

线程池的7大参数

- `corePoolSize`：核心线程数
- `maximumPoolSize`：最大线程数
- `keepAliveTime`：多余线程存活时间
- `timeUnit`：时间单位
- `workQueue`：阻塞队列
- `threadFactory`：线程工厂
- `rejectedHandler`：拒绝策略

#### 线程池中execute和submit的区别

> 1. execute只能接受Runnable类型的任务，submit不管是Runnable还是Callable类型的任务都可以接受，但是Runnable返回值均为void，所以使用Future的get()获得的还是null
> 2. submit()有返回值，而execute()没有
> 3. submit()可以进行Exception处理

### Spring

#### 说说你对Spring的理解

> Spring 是一款开源的轻量级 Java 开发框架，旨在提高开发人员的开发效率以及系统的可维护性。它是很多模块的集合，使用这些模块可以很方便地协助我们进行开发。比如说 Spring 自带 IoC（Inverse of Control:控制反转） 和 AOP(Aspect-Oriented Programming:面向切面编程)、可以很方便地对数据库进行访问、可以很方便地集成第三方组件（电子邮件，任务，调度，缓存等等）、对单元测试支持比较好、支持 RESTful Java 应用程序的开发。

#### 说说你对`AOP`的理解

> AOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。

#### 说说你对`IOC`的理解

> **IoC（Inverse of Control:控制反转）** 是一种设计思想，而不是一个具体的技术实现。IoC 的思想就是将原本在程序中手动创建对象的控制权，交由 Spring 框架来管理。不过， IoC 并非 Spirng 特有，在其他语言中也有应用。

#### 简述Spring Bean的生命周期

> 1. Spring启动，查找并加载需要被Spring管理的bean，进行Bean的实例化
> 2. Bean实例化后对将Bean的引入和值注入到Bean的属性中
> 3. 如果Bean实现了`BeanNameAware`接口的话，Spring将Bean的Id传递给`setBeanName()`方法
> 4. 如果Bean实现了`BeanFactoryAware`接口的话，Spring将调用`setBeanFactory()`方法，将`BeanFactory`容器实例传入
> 5. 如果Bean实现了`ApplicationContextAware`接口的话，Spring将调用Bean的`setApplicationContext()`方法，将bean所在应用上下文引用传入进来。
> 6. 如果Bean实现了`BeanPostProcessor`接口，Spring就将调用他们的`postProcessBeforeInitialization()`方法。
> 7. 如果Bean 实现了`InitializingBean`接口，Spring将调用他们的`afterPropertiesSet()`方法。类似的，如果bean使用`init-method`声明了初始化方法，该方法也会被调用
> 8. 如果Bean 实现了`BeanPostProcessor`接口，Spring就将调用他们的`postProcessAfterInitialization()`方法。
> 9. 此时，Bean已经准备就绪，可以被应用程序使用了。他们将一直驻留在应用上下文中，直到应用上下文被销毁。
> 10. 如果bean实现了`DisposableBean`接口，Spring将调用它的`destory()`接口方法，同样，如果bean使用了`destory-method `声明销毁方法，该方法也会被调用。

#### Spring中单例bean是否线程安全

> 有状态的bean：对象中有实例变量（成员变量），可以保存数据，是非线程安全的
>
> 无状态的bean：对象中没有实例变量（成员变量），不能保存数据，可以在多线程环境下共享，是线程安全的
>
> 在`spring`中，绝大部分bean都是无状态的，因此即使这些bean默认是单例的，也不会出现线程安全问题的。比如`controller`、`service`、`dao`这些类，这些类里面通常不会含有成员变量，因此它们被设计成单例的。如果这些类中定义了实例变量，就线程不安全了，所以尽量避免定义实例变量。
>
> 对于`spring`中有状态的bean，比如`RequestContextHolder`、`TransactionSynchronizationManager`、`LocaleContextHolder`，为什么也能够设计成单例的呢？它是怎么保证线程安全的？
>
> 对于有状态的bean，`spring`采用`ThreadLocal`进行处理，使它们成为线程安全可以共享的对象

#### `BeanFactory`和`ApplicationContext`的区别

> `BeanFactory`：是`Spring`里面最低层的接口，提供了最简单的容器的功能，只提供了实例化对象和拿对象的功能，`BeanFactory`启动时不会去实例化Bean，从容器中拿Bean的时候才会去实例化
>
> `ApplicationContext`：应用上下文，继承了`BeanFactory`接口，是`Spring`中的一个更高级的容器，启动时实例化所有`Bean`，可以配置延迟加载来延迟实例化，提供了更多的功能
>
> 国际化、资源访问、载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的web层、消息发送、响应机制（`ApplicationEventPublisher`）、`AOP`（拦截器）

#### 说说你对Spring MVC的理解

> MVC 是模型(Model)、视图(View)、控制器(Controller)的简写，其核心思想是通过将业务逻辑、数据、显示分离来组织代码。Spring MVC是对这种种思想的一个封装。

#### SpringMVC的工作流程

> 1. 用户发送请求至前端控制器`DispatcherServlet`
> 2. `DispatcherServlet`收到请求调用处理器映射器`HandlerMapping`。
> 3. 处理器映射器根据请求`url`找到具体的处理器，生成处理器执行链`HandlerExecutionChain`(包括处理器对象和处理器拦截器)一并返回给`DispatcherServlet`。
> 4. `DispatcherServlet`根据处理器`Handler`获取处理器适配器`HandlerAdapter`执行`HandlerAdapter`处理一系列的操作，如：参数封装，数据格式转换，数据验证等操作
> 5. 执行处理器`Handler`(`Controller`，也叫页面控制器)。
> 6. `Handler`执行完成返回`ModelAndView`
> 7. `HandlerAdapter`将`Handler`执行结果`ModelAndView`返回到`DispatcherServlet`
> 8. `DispatcherServlet`将`ModelAndView`传给`ViewReslover`视图解析器
> 9. `ViewReslover`解析后返回具体`View`
> 10. `DispatcherServlet`对`View`进行渲染视图（即将模型数据`model`填充至视图中）。
> 11. `DispatcherServlet`响应用户。

#### `SpringMVC`九大内置组件

> 1. `HandlerMapping(`处理器映射器)
>
>      寻找Handler(注解/配置文件/接口)
>
> 2. `HandlerAdapter`(处理器适配器)
> 
>      处理找到的`Handler`,因为`Handler`的实现多种多样,所以对于`Handler`不同的内部结构需要进行一定的处理容器在初始化的时候会自动帮我们注入 (也可以自己配置)`RequestMappingHandlerAdapter` `HttpRequestHandlerAdapter` 和`SimpleControllerHandlerAdapter`这三个配置器。
>  
> 3. `HandlerExceptionResolver`(异常处理器)
>
>      当我们在寻找和处理Handler时难免会出现一些问题(异常),这个时候就需要一个专门来处理异常的角色
>
> 4. `ViewResolver`(视图解析器)
>
>      用来渲染页面的,而`ViewResolver`所要做的就是找到渲染所用的模板和技术(页面类型)
>
> 5. `RequestToViewNameTranslator`(视图名称翻译器)
>
>      当没有`ViewName`时,从请求中解析获取视图名
>
> 6. `LocaleResolver`(当前环境处理器)
>
>      协助view的解析
>
>      - 一是ViewResolver视图解析的时候；
>      - 二是用到国际化资源或者主题的时候。
>
> 7. `ThemeResolver`(主题处理器)
>
>      主题处理器用于解析主题,相当于解析系统的整体样式和风格.
>
> 8. `MultipartResolver`(文件处理器)
>
>      用于处理上传请求。处理方法是将普通的`request`包装成`MultipartHttpServletRequest`，后者可以直接调用`getFile`方法获取File，如果上传多个文件，还可以调用`getFileMap`得到`FileName->File`结构的`Map`。此组件中一共有三个方法，作用分别是判断是不是上传请求，将`equest`包装成`MultipartHttpServletRequest`、处理完后清理上传过程中产生的临时资源。
>
> 9. `FlashMapManager`(参数传递管理器)
>
>      请求重定向是的参数管理

#### Spring、SpringMVC、SprinBoot区别

> - Spring是一个一站式的轻量级java开发框架，核心是控制反转（IOC）和面向切面（AOP），Spring 是可以在 Java SE/EE 中使用的轻量级开源框架。
> - SpringBootspringboot是Spring开源框架下的子项目，是Spring的一站式解决方案，简化了spring的使用难度，遵循“约定优于配置”的原则，降低了对配置文件的要求，使得开发人员能够更容易得上手。
> - SpringMVC属于SpringFrameWork的后续产品，已经融合在Spring Web Flow里面。SpringMVC是一种web层mvc框架，用于替代servlet（处理|响应请求，获取表单参数，表单校验等。SpringMVC是一个MVC的开源框架，SpringMVC=struts2+spring，springMVC就相当于是Struts2加上Spring的整合。

#### `SpringBoot`自动装配原理

`SpringBoot`所有自动配置类都是在启动的时候进行扫描并加载，通过`spring.factories`可以找到自动配置类的路径，但是不是所有存在于`spring,factories`中的配置都进行加载，而是通过`@ConditionalOnClass`注解进行判断条件是否成立（只要导入相应的stater，条件就能成立），如果条件成立则加载配置类，否则不加载该配置类。

- `SpringBoot`在启动的时候从类路径下的`META-INF/spring.factories`中获取`EnableAutoConfiguration`指定的值
- 将这些值作为自动配置类导入容器 ， 自动配置类就生效 ， 帮我们进行自动配置工作；
- 以前我们需要自己配置的东西 ， 自动配置类都帮我们解决了
- 整个`J2EE`的整体解决方案和自动配置都在`springboot-autoconfigure`的jar包中；
- 它将所有需要导入的组件以全类名的方式返回 ， 这些组件就会被添加到容器中 ；
- 它会给容器中导入非常多的自动配置类 `xxxAutoConfiguration`, 就是给容器中导入这个场景需要的所有组件 ，并配置好这些组件 ；
- 有了自动配置类 ， 免去了我们手动编写配置注入功能组件等的工作；

#### `Spring`的核心

`IOC(Inverse of Control 控制反转)`：传统的`java`开发模式中，当需要一个对象时我们，我们会自己使用`new`或者`getInstance`等直接或者间接调用构造方法创建一个对象，而在Spring开发模式中，Spring容器使用了工厂模式为我们创建了所需要的对象，我们使用时不需要自己去创建，直接调用Spring为我们提供的对象即可，这就是控制反转的思想。实例化一个`java`对象有三种方式：使用类构造器，使用静态工厂方法，使用实例工厂方法，当使用spring时我们就不需要关心通过何种方式实例化一个对象，spring通过控制反转机制自动为我们实例化一个对象。

`AOP(Aspect Oriented Programming 面向切面编程)`：在面向对象编程(OOP)思想中，我们将事物纵向抽象成一个个的对象。而在面向切面编程中，我们将一个个对象某些类似的方面横向抽象成一个切面，对这个切面进行一些如权限验证，事物管理，记录日志等公用操作处理的过程就是面向切面编程的思想。

#### Spring的事务传播机制

一个事务方法运行在一个开启了事务的方法中时，当前方法是使用原来的事务还是开启一个新事务。

Spring支持7种传播属性

- `Propagation.REQUIRED（required）`：支持当前事务，如果当前有事务， 那么加入事务， 如果当前没有事务则新建一个(默认情况)
- `Propagation.NOT_SUPPORTED（not_supported) `： 以非事务方式执行操作，如果当前存在事务就把当前事务挂起，执行完后恢复事务（忽略当前事务）；
- `Propagation.SUPPORTS (supports) `：如果当前有事务则加入，如果没有则不用事务。
- `Propagation.MANDATORY (mandatory) `：支持当前事务，如果当前没有事务，则抛出异常。（当前必须有事务）
- `PROPAGATION_NEVER (never)` ：以非事务方式执行，如果当前存在事务，则抛出异常。（当前必须不能有事务）
- `Propagation.REQUIRES_NEW (requires_new) `：支持当前事务，如果当前有事务，则挂起当前事务，然后新创建一个事务，如果当前没有事务，则自己创建一个事务。
- `Propagation.NESTED (nested 嵌套事务) ` ：如果当前存在事务，则嵌套在当前事务中。如果当前没有事务，则新建一个事务自己执行（和required一样）。嵌套的事务使用保存点作为回滚点，当内部事务回滚时不会影响外部事物的提交；但是外部回滚会把内部事务一起回滚回去。（这个和新建一个事务的区别）

#### Spring中使用了哪些设计模式及应用场景

- 工厂方法：实现`FactoryBean`接口
- 单例模式：`Spring`依赖注入Bean实例默认单例
- 适配器模式：`SpringMVC`中的适配器`HandlerAdatper`
- 装饰器模式：`Spring`中用到的包装器模式在类名上有两种表现：一种是类名中含有Wrapper，另一种是类名中含有Decorator。
- 代理模式：`AOP`底层，使用动态代理实现
- 观察者模式：spring的事件驱动模型使用的是观察者模式，Spring中Observer模式常用的地方是listener的实现。
- 模版方法：父类定义了骨架（调用哪些方法及顺序），某些特定方法由子类实现 

#### Spring事务的隔离级别有哪些

1. `DEFAULT` （默认） 

   这是一个`PlatfromTransactionManager`默认的隔离级别，使用数据库默认的事务隔离级别。另外四个与`JDBC`的隔离级别相对。

2. `READ_UNCOMMITTED `（读未提交）

3. `READ_COMMITTED `（读已提交）

4. `REPEATABLE_READ `（可重复读）

5. `SERIALIZABLE`（串行化）

#### Spring事务的实现原理

> Spring事务的本质其实就是数据库对事务的支持，没有数据库的事务支持，Spring是无法提供事务功能的。
>
> 我们经常使用的JPA、mybatis等数据库访问技术都有事务的处理机制，他们提供了用来开启事务，提交事务，回滚事务登相关API。Spring中提供了一个叫做PlatformTransactionManager接口，不同的数据库访问技术都会对改接口进行实现。
>
> Spring的使用声明式事务是通过AOP实现的，编程式事务通过TransactionManager。

#### Spring事务什么时候会失效

1. spring的事务注解@Transactional只能放在public修饰的方法上才起作用，如果放在其他非public（private，protected）方法上，虽然不报错，但是事务不起作用
2. 如使用mysql且引擎是MyISAM，则事务会不起作用，原因是MyISAM不支持事务，可以改成InnoDB引擎
3. 在业务代码中如果抛出RuntimeException异常，事务回滚；但是抛出Exception，事务不回滚
4. 代码中进行了异常捕获，没有抛出异常，事务也不会回滚。
5. 非事务方法调用本类的注解事务方法，事务会失效，因为同一个类中，方法互相调用，切面无效，注解事务是通过AOP实现的。

#### Spring是如何简化开发的

1. 基于POJO的轻量级和最小侵入性编程；
2. 通过依赖注入（DI）和面向接口实现松耦合；
3. 基于切面和惯例进行切面式编程；
4. 通过切面和模板减少样本式代码；

#### Spring支持的bean作用域有哪些

1. `singleton`作用域
2. `prototype`作用域
3. `request`作用域
4. `session`作用域
5. `global session`作用域

#### 如何理解Spring的starter

#### 如何实现一个`IOC`容器

1. 配置配置文件，定义bean信息
2. 加载配置文件，将读取到的bean信息封装`BeanDefination`
3. 根据`BeanDefination`反射生成Bean
4. 对Bean进行依赖注入

#### 什么是自动装配，它有哪些方式

Spring可以通过`@AutoWired`或者`xml`方式自动注入我们需要的依赖

#### 使用Spring的优势

1. 通过`IOC`容器和依赖注入，大大降低了代码的耦合和侵入性
2. 支持`AOP`编程
3. 支持声明式事务
4. 方便集成各种优秀框架
5. 对`Java EE`开发中的一些`API`提供了封装，降低了应用难度
6. 非侵入式减少应用程序对框架的依赖

#### SpringCloud的核心组件有哪些，分别有什么作用

1. Eureka：服务的注册与发现
2. Feign：基于动态代理和HTTP的远程调用
3. Ribbon：实现负载均衡
4. Hystrix：服务降级、熔断
5. gateway：网关路由，提供路由、鉴权、监控、限流、缓存等功能

#### 微服务架构的原理是什么

**概念：** 把一个大型的单个应用程序和服务拆分为数个甚至数十个的支持微服务，它可扩展单个组件而不是整个的应用程序堆栈，从而满足服务等级协议。

**定义：** 围绕业务领域组件来创建应用，这些应用可独立地进行开发、管理和迭代。在分散的组件中使用云架构和平台式部署、管理和服务功能，使产品交付变得更加简单。

**本质：** 用一些功能比较明确、业务比较精练的服务去解决更大、更实际的问题。

#### 注册中心的原理是什么

1. 各个微服务启动时，将自己的网络地址，服务名称等信息注册到注册中心，注册中心存储这些数据
2. 服务消费者从注册中心查询服务提供者的地址，并通过获取的地址调用服务
3. 各个微服务与注册中心通过一定的机制（例如心跳）通信，如果注册中心与某个微服务长时间无法通信，就会下线该实例

#### 配置中心是什么

在服务运行之前，将所需配置从配置仓库拉取到本地服务，达到统一化配置管理，方便集群扩容

#### 配置中心是如何实现自动刷新的

#### 用zookeeper和Eureka做注册中心有什么区别

Zookeeper 保证 CP

> Zookeeper 是保证数据的一致性的，但是并不是强一致的。
>
> 比如客户端 A 提交一个写操作，Zookeeper 在过半数节点操作成功之后就可以返回，但此时，客户端 B 的读操作请求的是 A 写操作尚未同步到的节点，那么读取的就不是 A 最新提交的数据了。我们可以在读取数据的时候先执行一下 sync 操作，即与 leader 节点先同步一下数据，再去取，这样才能保证数据的强一致性。
>
> 关于可用性，Zookeeper 的 master 节点因为网络故障与其他节点失去联系时，剩余节点会重新进行 leader 选举，选举  leader 的时间太长，需要 30 ~ 120 s, 且选举期间整个 Zookeeper  集群都是不可用的，这就导致在选举期间注册服务瘫痪。同时，在云部署的环境下，因网络问题使得 Zookeeper 集群失去 master  节点是较大概率会发生的事，整个服务停下这么长的时间是非常严重的，比如双十一。

Eureka 保证 AP

> 就是针对 Zookeeper 出现的这一问题，Eureka选择了优先保证可用性。
>
> 大规模网络部署时，失败是在所难免的。当向注册中心查询服务列表时，我们可以容忍注册中心返回的是几分钟以前的注册信息，但不能接受服务直接  down 掉不可用。而集群部署的 Eureka  即使挂掉一定的数量，也可以保证有信息可以返回，依然可以提供注册和查询服务，只不过查到的信息可能不是最新的。

#### `SpringCloud`和`Dubbo`有哪些区别

1. dubbo由于是二进制的传输，占用带宽会更少
2. springCloud是http协议传输，带宽会比较多，同时使用http协议一般会使用JSON报文，消耗会更大
3. dubbo的开发难度较大，原因是dubbo的jar包依赖问题很多大型工程无法解决
4. springcloud的接口协议约定比较自由且松散，需要有强有力的行政措施来限制接口无序升级
5. dubbo的注册中心可以选择zk,redis等，springcloud的注册中心用eureka或者Consul

#### Ribbon负载均衡原理是什么

#### 微服务熔断降级机制是什么

> 1. 当调⽤出现问题时，开启⼀个时间窗（10s）
> 2. 在这个时间窗内，统计调⽤次数是否达到最⼩请求数？如果没有达到，则重置统计信息，回到第1步如果达到了，则统计失败的请求数占所有请求数的百分⽐，是否达到阈值？ 如果达到，则跳闸（不再请求对应服务） 如果没有达到，则重置统计信息，回到第1步
> 3. 如果跳闸，则会开启⼀个活动窗⼝（默认5s），每隔5s，Hystrix会让⼀个请求通过,到达那个问题服务，看 是否调⽤成功，如果成功，重置断路器回到第1步，如果失败，回到第3步

#### OpenFeign配置

```yml
feign:
 compression:
 request:
 enabled: true # 开启请求压缩
 mime-types: text/html,application/xml,application/json # 设置压缩的数据类
型，此处也是默认值
 min-request-size: 2048 # 设置触发压缩的⼤⼩下限，此处也是默认值
 response:
 enabled: true # 开启响应压缩
logging:
 level:
 # Feign⽇志只会对⽇志级别为debug的做出响应
 com.lagou.edu.controller.service.ResumeServiceFeignClient: debug

```

#### OpenFeign中Ribbon配置有哪些

```yml
#针对的被调⽤⽅微服务名称,不加就是全局⽣效
lagou-service-resume:
 ribbon:
 #请求连接超时时间
 #ConnectTimeout: 2000
 #请求处理超时时间
 #ReadTimeout: 5000
 #对所有操作都进⾏重试
 OkToRetryOnAllOperations: true
 ####根据如上配置，当访问到故障请求的时候，它会再尝试访问⼀次当前实例（次数由
MaxAutoRetries配置），
 ####如果不⾏，就换⼀个实例进⾏访问，如果还不⾏，再换⼀次实例访问（更换次数由
MaxAutoRetriesNextServer配置），
 ####如果依然不⾏，返回失败信息。
 MaxAutoRetries: 0 #对当前选中实例重试次数，不包括第⼀次调⽤
 MaxAutoRetriesNextServer: 0 #切换实例的重试次数
 NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RoundRobinRule #负载
策略调整
```

#### OpenFeign中Hystrix配置有哪些

1. 开启Hystrix之后，Feign中的⽅法都会被进⾏⼀个管理了，⼀旦出现问题就进⼊对应的回退逻辑处理
2. 针对超时这⼀点，当前有两个超时时间设置（Feign/hystrix），熔断的时候是根据这两个时间的最⼩值来进⾏的，即处理时⻓超过最短的那个超时时间了就熔断进⼊回退降级逻辑

```yml
# 开启Feign的熔断功能
feign:
 hystrix:
 enabled: true
hystrix:
 command:
 default:
 execution:
 isolation:
 thread:
 ##########################################Hystrix的超时时⻓设置
 timeoutInMilliseconds: 15000
 
 # 配置熔断策略：
hystrix:
 command:
 default:
 circuitBreaker:
 # 强制打开熔断器，如果该属性设置为true，强制断路器进⼊打开状态，将会拒绝所有的请求。 默认false关闭的
 forceOpen: false
 # 触发熔断错误⽐例阈值，默认值50%
 errorThresholdPercentage: 50
 # 熔断后休眠时⻓，默认值5秒
 sleepWindowInMilliseconds: 3000 
 # 熔断触发最⼩请求次数，默认值是20
 requestVolumeThreshold: 2 
 execution:
 isolation:
 thread:
 # 熔断超时设置，默认为1秒
 timeoutInMilliseconds: 2000
```

#### ZAB协议是什么

#### 注册中心挂了，或者服务挂了，应该如何处理

### MySQL

#### MVCC解决的问题是什么

> MVCC，全称Multi-Version Concurrency Control，即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。
>
> MVCC在MySQL InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读，一般解决不可重复读和幻读问题

#### MVCC实现原理是什么

> 实现原理主要是依赖记录中的3隔隐式字段，undo log，Read View来实现
>
> 1. 隐式字段：
>
>    每行记录除了我们自定义的字段外，还有数据库隐式定义的DB_TRX_ID，DB_ROLL_PTR，DB_ROW_ID字段
>
>    - DB_TRX_ID：记录最近修改（修改/插入）事务ID，记录创建这条记录、最后一次修改该记录的事务ID
>    - DB_ROLL_PTR：回滚指针，指向这条记录的上个版本。
>    - DB_ROW_ID：隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引。
>
> 2. undo log日志：
>
>    insert undo log：代表事务在insert新记录时产生的undo log，只在事务回滚时需要，并且在事务提交后可以被立即丢弃
>
>    update undo log：事务在进行update或者delete时产生的undo log，不仅在事务回滚时需要，在快照读时也需要。
>
> 3. Read View主要是用来做可见性判断的, 即当我们某个事务执行快照读的时候，对该记录创建一个Read View读视图，把它比作条件用来判断当前事务能够看到哪个版本的数据，既可能是当前最新的数据，也有可能是该行记录的undo log里面的某个版本的数据。

#### 事务的基本要素

1. 原子性：事务开始后，要么全部完成，要么全部放弃，是不可分割的整体
2. 一致性：事务开始结束后，数据库的完整性约束没有被破坏
3. 隔离性：同一时间，只能有一个事务请求数据，不同事务之间彼此没有任何干扰
4. 持久性：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚

#### `Mysql`的隔离级别有哪些

1. 读取未提交，可能产生脏读、不可重复读、幻读
2. 读取已提交，可能产生不可重复读、幻读
3. 可重复读，可能产生幻读
4. 串行化

#### `Mysql`复制的原理是什么

1. Master记录二进制日志， 每次提交事务完成数据更新前，Master将数据更新的时间记录到二进制日志中，`MySql`会按事务提交的顺序而非每条语句的执行顺序来记录二进制日志。再记录二进制日志后，主库会告诉存储引擎可以提交事务了。
2. Slave将Master的二进制日志复制到本地的中继日志中，首先，Slave会启动一个工作线程，成为I/O线程，  I/O线程跟Master建立一个普通的客户端链接，然后再Master上启动一个特殊的二进制转储（binlog  dump）线程（该线程没有对应的SQL命令），这个二进制转储线程会读取主库上的二进制日志中的事件。从库I/O线程将接受到时间记录到中继日志中。
3. 从库的SQL线程执行最后异步，该线程的从中继日志中读取事件并在从库执行，从而实现从库数据更新。

#### Mysql聚簇索引和非聚簇索引的区别

都是B+树的数据结构

- 聚簇索引：将数据存储和索引放在一起、并且是按照一定的顺序组织的，找到索引也就找到了数据，数据的物理存放顺序与索引顺序是一致的，即：只要索引是相邻的，那么对应的数据一定也是相邻的存放在磁盘上的。
- 非聚簇索引：叶子节点不存储数据，存储的是数据行地址，也就是说根据索引查找到数据行的位置再去磁盘查找数据，这就有点类似一本书的目录，比如要找到第三章第一节，那就现在目录里面查找，找到对应的页码后再去对应的页码看文章。

优势

- 查找通过聚簇索引可以直接获取到数据，相比非聚簇索引需要第二次查询(覆盖索引除外)效率要高
- 聚簇索引对范围查询的效率很高，因为其数据是按照大小排列的
- 聚簇索引适合用在排序场合，非聚簇索引不适合。

劣势

- 维护索引代价大，特别是插入新行或者主键被更新导致要分页的时候。建议在大量插入新行后，选择负载较低的时间段，通过OPTIMIZE TABLE优化表
- 表因为使用UUID作为主键，使数据存储稀疏，这就会出现聚簇索引有可能会比全表扫面更慢，所以建议使用int的auto_increment作为主键。
- 如果主键比较大的话，那辅助索引将会变得更大，因为辅助索引的叶子节点存储的是主键值，过长的主键值，会导致非叶子节点占用更多的物理空间

#### `Mysql`索引的基本原理

> 本质都是通过不断地缩小想要获取数据的范围来筛选出最终想要的结果，同时吧随机的事件变成顺序的事件，也就是说，有了这种索引机制，我们可以总是用同一种查找方式来锁定数据。

#### `MySQL`索引有哪些结构，各自优劣是什么

> mysql索引数据结构使用的是b+树。
>
> MyISAM引擎的索引方式叫做“非聚集”的，索引指向data域地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。
>
> InnoDB引擎中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。
>
> 因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。

#### `MySQL`锁的类型有哪些

#### `MySQL`发生锁表的情况

> 发生情况：锁表发生在insert  update 、delete 中
>
> 锁表的原理：数据库使用独占式封锁机制，当执行上面的语句时，对表进行锁住，直到发生commite 或者 回滚 或者退出数据库用户
>
> 锁表的原因：
>
> 1. A程序执行了对 tableA 的 insert ，并还未 commite时，B程序也对tableA 进行insert 则此时会发生资源正忙的异常 就是锁表
> 2. 第二、锁表常发生于并发而不是并行（并行时，一个线程操作数据库时，另一个线程是不能操作数据库的，cpu 和i/o 分配原则）
>
> 减少锁表的概率：减少insert 、update 、delete 语句执行到 commite 之间的时间。具体点批量执行改为单个执行、优化sql自身的非执行速度，如果异常对事物进行回滚
>

#### `MySQL`为什需要主从同步

1. 读写分离，使数据库能支撑更大的并发。
2. 主数据库宕机，可以将业务系统切换到从数据库上，避免数据丢失。

#### `MySQL`执行计划怎么看

#### 简述`MyISAM`和`InnoDB`的区别

1. `InnoDB`支持事务，`MyISAM`不支持事务。这是`MySQL`将默认存储引擎从`MyISAM`变成`InnoDB`的重要原因之一；
2. `InnoDB`支持外键，而`MyISAM`不支持。对一个包含外键的`InnoDB`表转为`MYISAM`会失败；
3. `InnoDB`是聚集索引，`MyISAM`是非聚集索引。聚簇索引的文件存放在主键索引的叶子节点上，因此`InnoDB`必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而`MyISAM`是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。
4. `InnoDB`不保存表的具体行数，执行`select count(*) from table`时需要全表扫描。而`MyISAM`用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快
5. `InnoDB`最小的锁粒度是行锁，`MyISAM`最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 `MySQL`将默认存储引擎从`MyISAM`变成`InnoDB`的重要原因之一

#### 简述MySQL中索引类型有哪些，以及对数据库的性能影响

物理角度

1. 聚簇索引
2. 非聚簇索引

从逻辑角度

1. 主键索引：主键索引是一种特殊的唯一索引，不允许有空值
2. 普通索引或者单列索引
3. 多列索引（复合索引）：复合索引指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用复合索引时遵循最左前缀集合
4. 唯一索引或者非唯一索引

#### 如何处理`MySQL`的慢查询

1. EXPLAIN

   做`MySQL`优化，我们要善用`EXPLAIN`查看`SQL`执行计划。

   - type列，连接类型。一个好的SQL语句至少要达到range级别。杜绝出现all级别。
   - key列，使用到的索引名。如果没有选择索引，值是NULL。可以采取强制索引方式。
   - key_len列，索引长度。
   - rows列，扫描行数。该值是个预估值。
   - extra列，详细说明。注意，常见的不太友好的值，如下：Using filesort，Using temporary。

2. `SQL`语句中IN包含的值不应过多

   `MySQL`对于IN做了相应的优化，即将IN中的常量全部存储在一个数组里面，而且这个数组是排好序的。但是如果数值较多，产生的消耗也是比较大的。再例如：`select id from t where num in(1,2,3) `对于连续的数值，能用`between`就不要用`in`了；再或者使用连接来替换。

3. SELECT语句务必指明字段名称

   `SELECT*`增加很多不必要的消耗（CPU、IO、内存、网络带宽）；增加了使用覆盖索引的可能性；当表结构发生改变时，前断也需要更新。所以要求直接在`select`后面接上字段名。

4. 当只需要一条数据的时候，使用`limit 1`

5. 如果排序字段没有用到索引，就尽量少排序

6. 如果限制条件中其他字段没有索引，尽量少用or

   or两边的字段中，如果有一个不是索引字段，而其他条件也不是索引字段，会造成该查询不走索引的情况。很多时候使用union all或者是union（必要的时候）的方式来代替“or”会得到更好的效果。

7. 尽量用union all代替union

   union和union all的差异主要是前者需要将结果集合并后再进行唯一性过滤操作，这就会涉及到排序，增加大量的CPU运算，加大资源消耗及延迟。当然，union all的前提条件是两个结果集没有重复数据。

8. 区分in和exists、not in和not exists

   区分in和exists主要是造成了驱动顺序的改变（这是性能变化的关键），如果是exists，那么以外层表为驱动表，先被访问，如果是IN，那么先执行子查询。所以IN适合于外表大而内表小的情况；EXISTS适合于外表小而内表大的情况。

9. 分段查询

   在一些用户选择页面中，可能一些用户选择的时间范围过大，造成查询缓慢。主要的原因是扫描行数过多。这个时候可以通过程序，分段进行查询，循环遍历，将结果合并处理进行展示。

10. 避免在where子句中对字段进行null值判断

    对于null的判断会导致引擎放弃使用索引而进行全表扫描。

11. 不建议使用%前缀模糊查询

12. 避免在where子句中对字段进行表达式操作

13. 对于联合索引来说，要遵守最左前缀法则

#### 什么是MVCC

#### 什么是`MySQL`主从复制

MySQL 主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。可以实现读写分离，让主库负责写，从库负责读，使数据层能支持更大的并发

#### 索引的设计原则有哪些

1. 设置合理的索引，否则不仅会占用大量的磁盘空间，而且还会影响`INSERT、DELETE、UPDATE`等语句的性能
2. 避免对经常更新的表进行过多的索引，并且索引中的列尽可能少。而对经常用于查询的字段应该创建索引，但要避免添加不必要的字段。
3. 据量小的表最好不要使用索引，由于数据较少，查询花费的时间可能比遍历索引的时间还要短，索引可能不会产生优化效果。
4. 在条件表达式中经常用到的、不同值较多的列上建立索引，在不同值较少的列上不要建立索引。
5. 当唯一性是某种数据本身的特征时，指定唯一索引。使用唯一索引能够确保定义的列的数据完整性，提供查询速度。
6. 在频繁进行排序和分组（GROUP BY或ORDER BY）的列上建立索引，如果排序的列有多个，可以在这些列上建立组合索引。

优化原则

1. 避免对列的操作。任何对列的操作都可能导致全表扫描，这里所谓的操作包括数据库函数、计算表达式等，查询时要尽可能将操作移至等式的右边，甚至去掉函数。
2. 避免不必要的类型转换
3. 增加查询的范围限制，避免全范围的查询
4. 尽量去掉`IN`、`OR`，使用`between`和`union`代替
5. 尽量去掉 <>
6. 去掉WHERE字句中的IS NULL和IS NOT NULL。WHERE字句中的IS NULL和IS NOT NULL将不会使用索引而是进行全表搜索。
7. LIKE字句尽量前段匹配

### Redis

#### 为什么要用 Redis/为什么要用缓存？

> 高频数据放在缓存中可以提高数据响应速度
>
> 缓存可以提高系统并发能力。

#### Redis 除了做缓存，还能做什么？

> - **分布式锁** ： 通过 Redis 来做分布式锁是一种比较常见的方式。通常情况下，我们都是基于 Redisson 来实现分布式锁。
> - **限流** ：一般是通过 Redis + Lua 脚本的方式来实现限流。
> - **消息队列** ：Redis 自带的 list 数据结构可以作为一个简单的队列使用。Redis5.0 中增加的 Stream 类型的数据结构更加适合用来做消息队列。它比较类似于 Kafka，有主题和消费组的概念，支持消息持久化以及 ACK 机制。
> - **复杂业务场景** ：通过 Redis 以及 Redis 扩展（比如 Redisson）提供的数据结构，我们可以很方便地完成很多复杂的业务场景比如通过 bitmap 统计活跃用户、通过 sorted set 维护排行榜。

#### redis持久化

- RDB模式

  指定时间间隔将内存中的数据快照写入到磁盘，也是Redis默认的持久化方式。

  - RDB文件紧凑，全量备份，适合备份和容灾恢复
  - 生成RDB文件的时候，redis主进程会fork()一个子进程来处理所有保存工作，主进程不需要进行任何磁盘IO操作。
  - RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。
  - 可能会丢失数据

- AOF机制

  将每一个收到的写命令都通过write函数追加到文件中。通俗的理解就是日志记录。

  - 可以更好的保护数据不丢失，一个设置间隔1秒，最对丢失1秒数据
  - AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据
  - AOF通常比RDB文件更大
  - 性能不如RDB，但还是很高

#### redis单线程为什么这么快，有哪些线程模型

1. 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；
2. 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；
3. 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
4. 使用多路I/O复用模型，非阻塞IO；

#### `redis`的过期键有哪些删除策略

**对于过期键一般有三种策略**

- 定时删除：在设置键的过期时间的同时，创建一个定时器(timer)，让定时器在键的过期时间来临时，立即执行对键的删除操作；
- 惰性删除：放任键过期不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键；如果没有过期，那就返回该键；
- 定期删除：每隔一段时间，程序就对数据库进行一次检查，删除里面的过期键。至于删除多少过期键，以及要检查多少个数据库，则由算法决定。

**`Redis`的过期键删除策略**：

1. 惰性删除
2. 定期删除

#### `redis`缓存如何回收

设置了`redis`的最大内存占用（`maxmemory`）后，当最大内存占用限制达到时，`redis`会使用缓存回收策略

1. `volatile-lru` -> 根据`LRU`算法删除设置了超时属性（expire）的键，直到腾出足够空间为止。如果没有可删除的键对象，回退到`noeviction`策略。
2. `allkeys-lru` -> 根据`LRU`算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。
3. `volatile-lfu` -> 根据`LFU`算法删除设置了超时属性（expire）的键，直到腾出足够空间为止。如果没有可删除的键对象，回退到`noeviction`策略。
4. `allkeys-lfu` -> 根据`LFU`算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。
5. `volatile-random` -> 随机删除过期键，直到腾出足够空间为止。
6. `allkeys-random` -> 随机删除所有键，直到腾出足够空间为止。
7. `volatile-ttl` -> 根据键值对象的`ttl`属性，删除最近将要过期数据。如果没有，回退到`noeviction`策略。
8. `noeviction` -> 不会删除任何数据，拒绝所有写入操作并返 回客户端错误信息，此 时`Redis`只响应读操作。

`LRU` (Least recently used) 最近最少使用，`LFU` (Least frequently used) 最不经常使用

#### `redis`集群有哪些方案

主从复制：

1. 主机自动将数据同步到从机，可以实现读写分离，分担主机压力。
2. 不具备自动容错和恢复功能，主从机宕机后需要手动重启或切换`IP`，主机宕机还有可能造成数据不一致问题。
3. `Redis`较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。

哨兵模式：

1. 哨兵模式基于主从复制，拥有它的所有有点，哨兵集群可以监视主从服务器，主服务器宕机后会自动选举从服务器代替
2. `Redis`较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。

`Redis-Cluster`集群：

`redis3.0`上加入了`cluster`模式，实现的`redis`的分布式存储，也就是说每台`redis`节点上存储不同的内容。

- 所有的`redis`节点彼此互联(`PING-PONG`机制),内部使用二进制协议优化传输速度和带宽。
- 节点的fail是通过集群中超过半数的节点检测失效时才生效。
- 客户端与`redis`节点直连,不需要中间代理层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可。

在`redis`的每一个节点上，都有这么两个东西，一个是插槽（slot），它的的取值范围是：0-16383。还有一个就是cluster，可以理解为是一个集群管理的插件。当我们的存取的key到达的时候，`redis`会根据`crc16`的算法得出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383  之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。

为了保证高可用，`redis-cluster`集群引入了主从模式，一个主节点对应一个或者多个从节点，当主节点宕机的时候，就会启用从节点。当其它主节点ping一个主节点A时，如果半数以上的主节点与A通信超时，那么认为主节点A宕机了。如果主节点A和它的从节点A1都宕机了，那么该集群就无法再提供服务了。

#### `redis`事务是如何实现的

`Redis`事务通常会使用`MULTI,EXEC,WATCH,DISCARD`等命令来完成,`redis`实现事务实现的机制与常见的关系型数据库有很大的区别,比如`redis`的事务不支持回滚,事务执行时会阻塞其它客户端的请求执行

事务由multi开启，将多个命令入队到事务中，最后exec命令触发事务

- **原子性**：对于`Redis`的事务功能来说，事务队列中的命令要么就全部执行，要么就一个都不执行，但是`Redis`的事务是不支持回滚操作的
- **一致性**：`Redis`通过谨慎的错误检测和简单的设计保证事务的一致性。`Redis`事务可能出错的地方以及解决方案：
  1. **入队错误**：如果一个事务在入队命令的过程中发现命令不存在或者命令格式不正确，`Redis`将拒绝执行这个事务
  2. **执行错误**：事务在执行的过程中发生错误的命令会被服务器识别出来，并进行相应的错误处理，所以这些出错的命令不会对数据库做任何修改，也不会对事务的一致性产生任何影响
  3. **服务器停机**：如果`Redis`服务器在执行事务的过程中停机，且服务器运行在任意模式下（无持久化的内存模式、`RDB`模式或者`AOF`模式），事务执行中途发生的停机都不会影响数据库的一致性
- **隔离性**：`Redis`使用单线程的方式执行事务，并且服务器保证在执行事务期间不会对事务进行中断，因此，`Redis`的事务总是串行的方式运行，并且事务总是具有隔离性的
- **持久性**：当服务器运行在`AOF`持久化模式下，并且`appendfsync`选项的值是`always`时，事务是具有耐久性的，其他情况不具有耐久性

#### `redis`主从复制原理

**全量同步**
`Redis`全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： 

- 从服务器连接主服务器，发送SYNC命令； 
- 主服务器接收到SYNC命名后，开始执行`BGSAVE`命令生成`RDB`文件并使用缓冲区记录此后执行的所有写命令； 
- 主服务器`BGSAVE`执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令；
- 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 
- 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 
- 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；

**增量同步**
`Redis`增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。 增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。

#### 缓存击穿、穿透、雪崩、预热解决方案

缓存穿透：

> 描述：访问一个缓存和数据库都不存在的 key，此时会直接打到数据库上，并且查不到数据，没法写缓存，所以下一次同样会打到数据库上。
>
> 此时，缓存起不到作用，请求每次都会走到数据库，流量大时数据库可能会被打挂。此时缓存就好像被“穿透”了一样，起不到任何作用。
>
> 解决方案：接口校验，布隆过滤器，缓存空值

缓存击穿：

> 描述：某一个热点 key，在缓存过期的一瞬间，同时有大量的请求打进来，由于此时缓存过期了，所以请求最终都会走到数据库，造成瞬时数据库请求量大、压力骤增，甚至可能打垮数据库。
>
> 解决方案：加互斥锁，设置热点数据不过期

缓存雪崩：

> 描述：大量的热点 key 设置了相同的过期时间，导在缓存在同一时刻全部失效，造成瞬时数据库请求量大、压力骤增，引起雪崩，甚至导致数据库被打挂。
>
> 缓存雪崩其实有点像“升级版的缓存击穿”，缓存击穿是一个热点 key，缓存雪崩是一组热点 key。
>
> 解决方案：打撒过期时间，设置热点数据不过期，加互斥锁

### zookeeper

#### zookeeper的watch机制是什么

#### zookeeper的命名、配置、管理是如何实现的

#### zookeeper的数据模型和节点类型

### kafka

#### 简述kafka架构设计

> Kafka采用**发布-订阅**消息模型。使用主题（Topic）作为消息通信载体，类似于广播模式，发布者发布一条消息，该消息通过主题传递给所有的订阅者。

#### Kafka 的多副本机制了解吗？带来了什么好处？

> Kafka的分区（Partition）可以有多个副本，多个副本中会有一个leader，其余副本为follower，我们发送的消息会被发送到leader中，然后follower副本从leader中同步消息。生产者和消费者只能与leader交互，其余副本只做安全备份。
>
> - Kafka通过给特定Topic指定多个Partition，而各个Partition可以分布在不同的Broker上，这样便能提供比较好的并发能力
> - Partition可以指定对应的副本数，极大地提高了消息存储的安全性，提高了容灾能力，不过也相应增加了所需要的存储空间。

#### kafka的rebalance机制是什么

#### kafka是pull还是push，分析一下优劣

> kafka采用的是pull方式
>
> push方式由broker决定消息推送的速率，对于不同消费速率的consumer不好处理
>
> pull方式consumer可以自主决定消费速率，决定是否批量拉取数据，但是当没有消息时，可能会导致consumer不断轮询。

#### kafka消息丢失的场景有哪些

生产者阶段：

> 生产者发送消息没有收到broker正确的响应，导致生产者重试。
>
> 生产者发送一条消息，broker落盘后因为网络等种种原因发送端得到一个发送失败的响应或者网络中断，然后生产者重试导致消息重复。
>
> 解决方案：启动kafka的幂等性；ack=0，不重试

生产者和broker阶段：

> ack=0，不重试，如果失败就会丢失消息
>
> ack=1，leader宕机，发送之后只等leader写入成功就返回成功，leader宕机时，还未同步消息，可能会消息丢失
>
> 解决方案：
>
> 1. 配置ack=all / -1,tries > 1,unclean.leader.election.enable : false
>
>    producer发送消息完，等待ollower同步完再返回，如果异常则重试。这时副本的数量可能影响吞吐量，最大不超过5个，一般三个足够了。不允许选举ISR以外的副本作为leader。
>
> 2. 配置：min.insync.replicas > 1
>
>    当producer将acks设置为“all”(或“-1”)时，min.insync。副本指定必须确认写操作成功的最小副本数量。如果不能满足这个最小值，则生产者将引发一个异常(要么是NotEnoughReplicas，要么是NotEnoughReplicasAfterAppend)。
>
> 3. 失败的offset单独记录
>
>    捕获失败的单独处理

消费者阶段：

> 数据消费完没有及时提交offset到broker
>
> 解决方案：取消自动提交改为手动几条

#### kafka中zookeeper作用是什么

broker

> zookeeper会记录所有broker的存活状态，broker会向zookeeper发送心跳请求来上报自己的状态，zookeeper维护了一个正在运行集群的broker列表
>
> 如果分区leader故障，zookeeper会负责选取新的分区leader。
>
> kafka 允许一些 client 有不同的生产和消费的限额。这些限额配置信息是保存在 zookeeper 里面的。所有 topic 的访问控制信息也是由 zookeeper 维护的。
>
> ISR（in-sync replica） 是 partition 的一组同步集合，就是所有 follower 里面同步最积极的那部分。一条消息只有被 ISR 中的成员都接收到，才被视为“已同步”状态。只有处于 ISR 集合中的副本才有资格被选举为 leader。zookeeper 记录着 ISR 的信息，而且是实时更新的，只要发现其中有成员不正常，马上移除。
>
> zookeeper 保存了所有 node 和 topic 的注册信息，可以方便的找到每个 broker 持有哪些 topic。node 和 topic 在 zookeeper 中是以临时节点的形式存在的，只要与 zookeeper 的 session 一关闭，他们的信息就没有了。
>
> zookeeper 保存了 topic 相关配置，例如 topic 列表、每个 topic 的 partition 数量、副本的位置等等。

消费者

> kafka 老版本中，consumer 的消费偏移量是默认存储在 zookeeper 中的。新版本中，这个工作由 kafka 自己做了，kafka 专门做了一个 offset manager。
>
> 和 broker 一样，consumer 也需要注册。consumer 会自动注册，注册的方式也是创建一个临时节点，consumer down 了之后就会自动销毁。
>
> kafka 的每个 partition 只能被消费组中的一个 consumer 消费，kafka 必须知道所有 partition 与 consumer 的关系。

#### kafka中高性能如何保障

分区

> 分区的设计使得Kafka消息的读写性能可以突破单台broker的I/O性能瓶颈，可以在创建主题的时候指定分区数，也可以在主题创建完成之后去修改分区数，通过增加分区数可以实现水平扩展，但是要注意，分区数也不是越多越好，一般达到某一个阈值之后，再增加分区数性能反而会下降，具体阈值需要对Kafka集群进行压测才能确定。

消息顺序追加

> Kafka是通过文件追加的方式来写入消息的，只能在日志文件的最后追加新的消息，并且不允许修改已经写入的消息，这种方式就是顺序写磁盘，而顺序写磁盘的速度是非常快的。

页缓存

> 页缓存是操作系统实现的一种主要的磁盘缓存，以此用来减少对磁盘I/O的操作。具体来说，就是把磁盘中的数据缓存到内存中，把对磁盘的访问变为对内存的访问。Kafka中大量使用了页缓存，消息都是先被写入页缓存，再由操作系统负责具体的刷盘任务（Kafka中也提供了同步刷盘和间断性强制算盘的功能）。

零拷贝

> 零拷贝技术是一种避免CPU将数据从一块存储拷贝到另一块存储的技术。Kafka使用零拷贝技术将数据直接从磁盘复制到网卡设备缓冲区中，而不需要经过应用程序的转发。通常应用程序将磁盘上的数据传送至网卡需要经过4步：
>
> 1. 调用read()，将数据从磁盘复制到内核模式的缓冲区；
> 2. CPU会将数据从内核模式复制到用户模式下的缓冲区；
> 3. 调用write()，将数据从用户模式下复制到内核模式下的Socket缓冲区；
> 4. 将数据从内核模式的Socket缓冲区复制到网卡设备。
>
> 上面的步骤中，第2、3步将数据从内核模式经过用户模式再绕回内核模式，浪费了两次复制过程。采用零拷贝技术，Kafka可以直接请求内核把磁盘中的数据复制到Socket缓冲区，而不用再经过用户模式。

### RabbitMq

#### rabbitmq的架构设计

#### rabbitmq的事务消息处理

#### rabbitmq如何保证消息的发送和接收

#### rabbitmq死信队列，延迟队列

### Mybatis

#### `Mybatis`的优缺点有哪些

`Mybatis`是一个半自动的`ORM`持久层框架，内部封装了`JDBC`。作为开发者只需要关注`sql`语句本身。`Mybatis`是通过`xml`或注解的方式将需要执行的各种`statement`配置起来。通过`Java`对象和`statement`中的`sql`动态参数映射生成最终执行的`sql`语句，最终由`Mabtais`框架执行`sql`并将结果映射为`Java`对象并返回。`MyBatis`支持定制化`SQL`、存储过程以及高级映射。`MyBatis`是可以双向映射的，可以将数据集映射为`Java`对象，也可以将`Java`对象映射为数据库中的记录。

优点：

- 简单易上手
- 消除了`JDBC`大量冗余代码
- 兼容各种数据库
- 提供很多第三方插件
- 和Spring集成性好
- `sql`和代码解耦
- 支持动态`sql`
- 支持对象与数据`ORM`字段关系映射

缺点：

- `sql`编写量大，要求一定`sql`功底
- `sql`依赖数据库，可移植性差，不能随意更换数据库

#### Mybatis和hibernate的区别

#### `Mybatis`中#{}和${}的区别

- `Mybatis`在处理#{}时，会将`sql`中的#{}替换为?号，调用`PreparedStatement`的 set 方法来赋值，使用#{}可以有效的防止`SQL`注入，提高系统安全性。
- `Mybatis`在处理${}时，使用的是字符串拼接

#### Mybatis插件的运行原理和开发流程

> Mybatis插件又称拦截器，Mybatis采用责任链模式，通过动态代理组织多个插件（拦截器），通过这些插件可以改变Mybatis的默认行为。MyBatis 允许你在已映射语句执行过程中的某一点进行拦截调用。默认情况下，MyBatis允许使用插件来拦截的方法调用包括：
> 1. Executor (update, query, flushStatements, commit, rollback,getTransaction, close, isClosed) 拦截执行器的方法；
> 2. ParameterHandler (getParameterObject, setParameters) 拦截参数的处理；
> 3. ResultSetHandler (handleResultSets, handleOutputParameters) 拦截结果集的处理；
> 4. StatementHandler (prepare, parameterize, batch, update, query) 拦截Sql语法构建的处理；
>
> 开发方式
>
> Mybatis的插件实现要实现Interceptor接口，这个接口只声明了三个方法。
>
> 1. setProperties方法是在Mybatis进行配置插件的时候可以配置自定义相关属性，即：接口实现对象的参数配置
> 2. plugin方法是插件用于封装目标对象的，通过该方法我们可以返回目标对象本身，也可以返回一个它的代理，可以决定是否要进行拦截进而决定要返回一个什么样的目标对象，官方提供了示例：return Plugin.wrap(target, this);
> 3. intercept方法就是要进行拦截的时候要执行的方法
>
> ```java
> @Intercepts({@Signature(type = Executor.class, method = "query",
>         args = {MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class})})
> public class TestInterceptor implements Interceptor {
>     public Object intercept(Invocation invocation) throws Throwable {
>         Object target = invocation.getTarget(); //被代理对象
>         Method method = invocation.getMethod(); //代理方法
>         Object[] args = invocation.getArgs(); //方法参数
>         // do something ...... 方法拦截前执行代码块
>         Object result = invocation.proceed();
>         // do something .......方法拦截后执行代码块
>         return result;
>     }
>     public Object plugin(Object target) {
>         return Plugin.wrap(target, this);
>     }
> }
> ```
>
> 

### elasticsearch

#### 倒排索引是什么

传统检索是通过文章，逐个遍历找到对应的关键词的位置。而倒排索引，是通过分词策略，形成词和文章的映射关系表，这种词典+映射表就是倒排索引，可以实现o(1)时间复杂度的效率检索文章，极大的提高了检索效率。
